{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo utilizado para procesar la base de datos con la que trabajaremos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos Datos Privados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levanto la base de datos privados con la que trabajeremos\n",
    "df_k = pd.read_csv('base_kavak.csv', sep=\";\")\n",
    "\n",
    "# Observamos nuestro dataset\n",
    "df_k.info()\n",
    "df_k.shape\n",
    "# (2532, 15)\n",
    "\n",
    "# Armo una lista de los modelos disponibles en el dataset\n",
    "modelos = df_k['modelo'].unique().tolist()\n",
    "# 146 modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos Datos Públicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levanto la base de datos públicos con la que trabajeremos\n",
    "df = pd.read_csv('data_publications.csv', sep=\";\")\n",
    "\n",
    "# Observamos nuestro dataset\n",
    "df.info()\n",
    "df.shape\n",
    "# (51360, 9)\n",
    "\n",
    "# Evaluamos si tiene duplicados\n",
    "print(df.duplicated().sum())\n",
    "# 7624 filas duplicadas\n",
    "\n",
    "# Sacamos los valores duplicados\n",
    "df_new = df.drop_duplicates()\n",
    "df_new.shape\n",
    "# (43736, 9)\n",
    "\n",
    "# Evaluamos si tiene nulos\n",
    "df_new.isna().sum().sort_values()\n",
    "# provincia      9\n",
    "\n",
    "# Sacamos aquellas publicadas con valor en Dolares\n",
    "df_new_ars = df_new.drop(df_new[df_new['currency']=='U$S'].index)\n",
    "\n",
    "df_new_ars.shape\n",
    "df_new_ars.info()\n",
    "df_new_ars.describe()\n",
    "# (35705, 9)\n",
    "\n",
    " \n",
    "# Sumamos la columna modelo al data set público (a partir de los datos privados)\n",
    "df_new_ars['modelo'] = pd.NaT\n",
    "i = 0\n",
    "for t in df_new_ars['title']:\n",
    "    for m in modelos:\n",
    "        if m.lower() in t.lower():\n",
    "            df_new_ars['modelo'][i] = m\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "  \n",
    "# Vemos la forma\n",
    "df_new_ars.shape\n",
    "# (35705, 10)\n",
    "\n",
    "\n",
    "# Evaluo valores con nulos\n",
    "df_new_ars.isna().sum().sort_values()\n",
    "# provincia         8\n",
    "# modelo         14711\n",
    " \n",
    "# Eliminamos los valores con modelo nulo\n",
    "df_new_ars = df_new_ars.drop(df_new_ars[df_new_ars['modelo'].isna()].index)\n",
    "df_new_ars = df_new_ars.drop('title',axis=1)\n",
    "\n",
    "df_new_ars.shape\n",
    "# (20994, 9)\n",
    "\n",
    "\n",
    "# Guardamos la información en un csv\n",
    "# df_new_ars.to_csv('data_publications_process.csv',mode='a', sep=';', encoding='utf-8-sig', index=False)\n",
    "# datos.to_excel('data_ready_to_model.csv',mode='a', sep=';', encoding='utf-8-sig', index=False)\n",
    "#%%\n",
    "# Exporto a un Excel\n",
    "datos = df_new_ars\n",
    "datos.to_excel('data_ready_to_model.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################## Limpieza de datos##\n",
    "######################################################################\n",
    "\n",
    "# 1 - Sacamos los outliers\n",
    "\n",
    "# Función que termina los outliers\n",
    "def outlier_treatment(df,datacolumn):\n",
    "    sorted(datacolumn)\n",
    "    Q1,Q3 = np.percentile(datacolumn , [25,75])\n",
    "    IQR = Q3 - Q1\n",
    "    lower_range = Q1 - (1.5 * IQR)\n",
    "    upper_range = Q3 + (1.5 * IQR)\n",
    "    df.drop(df[(datacolumn < lower_range) | (datacolumn > upper_range)].index, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Saco outlier KM\n",
    "# datos = outlier_treatment(datos, datos.km)\n",
    "# datos.shape\n",
    "# (30808, 10)\n",
    "\n",
    "# Saco outlier Year\n",
    "# datos = outlier_treatment(datos, datos.year)\n",
    "# datos.shape\n",
    "# (30404, 10)\n",
    "\n",
    "# Saco outlier Price\n",
    "# datos = outlier_treatment(datos, datos.precio)\n",
    "# datos.shape\n",
    "# (28600, 10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3e9a750fc05e5a08aac5c7f68a373d320e024e5143e44a9c92a2cb2852add95"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Levantamos los datos procesados\n",
    "df = pd.read_csv('data_ready_to_model.csv', sep=\";\")\n",
    "\n",
    "# Observamos nuestro dataset\n",
    "df.info()\n",
    "df.shape\n",
    "df.isna().sum().sort_values()\n",
    "df = df.drop('title',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos grupos de Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the other attributes from the predicting attribute\n",
    "x = df.drop('precio',axis=1)\n",
    "print(x)\n",
    "type(x)\n",
    "x = one_hot_encoder(x,10)\n",
    "X = pd.DataFrame(x, columns=x.feature_names)\n",
    "#separte the predicting attribute into Y for model training \n",
    "y = df['precio']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miramos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xg_reg.predict(X_test)\n",
    "\n",
    "print('Mean Absolute Error:', round(metrics.mean_absolute_error(y_test, y_pred)/1000000,2))\n",
    "# MAE: Mean Absolute Error: 1.08\n",
    "# MAE: Mean Absolute Error: 0.87\n",
    "print('Mean Squared Error:', round(metrics.mean_squared_error(y_test, y_pred)/1000000,2))\n",
    "# MSE: Mean Squared Error: 7,272,534.09\n",
    "# MSE: Mean Squared Error: 1,430,040.43\n",
    "print('Root Mean Squared Error:', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred))/1000000,2))\n",
    "# Root Mean Squared Error: 2.7\n",
    "# Root Mean Squared Error: 1.2\n",
    "\n",
    "\n",
    "# Miro la importancia de las variables\n",
    "importance = xg_reg.feature_importances_\n",
    "x.columns\n",
    "figure(figsize=(15, 4.5), dpi=80,)\n",
    "plt.bar(x.columns, xg_reg.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizamos parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## Optimizando los hiperparametros\n",
    "########################################## GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'max_depth': [3,6,10],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.7]}\n",
    "\n",
    "xgbr = xgb.XGBRegressor(seed = 20)\n",
    "clf_GS = GridSearchCV(estimator=xgbr, \n",
    "                   param_grid=params,\n",
    "                   # scoring='neg_mean_squared_error',\n",
    "                   scoring = 'neg_mean_absolute_error'\n",
    "                   verbose=1)\n",
    "clf_GridS.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "\n",
    "y_pred_test = clf_GridS.best_estimator_(X_test)\n",
    "y_pred_train = clf_GridS.best_estimator_(X_train)\n",
    "\n",
    "print('Root Mean Squared Error:', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_test))/1000000,2))\n",
    "print('Root Mean Squared Error:', round(np.sqrt(metrics.mean_squared_error(y_train, y_pred_train))/1000000,2))\n",
    "\n",
    "\n",
    "# Best parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 1000}\n",
    "print(\"Lowest RMSE: \", round(((-clf_GridS.best_score_)**(1/2.0)/1000000),2))\n",
    "# Lowest RMSE:  0.44\n",
    "print(\"Lowest MSE: \", round((-clf_GridS.best_score_/1000000),2))\n",
    "# Lowest MSE:  197.270.95\n",
    "\n",
    "########################################## RandomSearch\n",
    "\n",
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 500, 1000]}\n",
    "\n",
    "xgbr = xgb.XGBRegressor(seed = 20)\n",
    "clf_RandomS = RandomizedSearchCV(estimator=xgbr,\n",
    "                         param_distributions=params,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         n_iter=25,\n",
    "                         verbose=1)\n",
    "clf_RandomS.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", clf_RandomS.best_params_)\n",
    "# print(\"Best parameters:\", clf_RandomS.best_params_)\n",
    "# Best parameters: {'subsample': 0.8999999999999999, 'n_estimators': 500, 'max_depth': 15, 'learning_rate': 0.2, 'colsample_bytree': 0.8999999999999999, 'colsample_bylevel': 0.7}\n",
    "print(\"Lowest RMSE: \", round(((-clf_RandomS.best_score_)**(1/2.0)/1000000),2))\n",
    "# Lowest RMSE:  0.46\n",
    "print(\"Lowest MSE: \", round((-clf_RandomS.best_score_/1000000),2))\n",
    "# Lowest MSE:  213.030.49"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3e9a750fc05e5a08aac5c7f68a373d320e024e5143e44a9c92a2cb2852add95"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
